{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa1f6b9-da73-4d8c-b25a-72ba5c5f0155",
   "metadata": {},
   "source": [
    "# **USE CASE 1.** Image classification in Flower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e298973-2d25-498a-93bf-f50da959a6b7",
   "metadata": {},
   "source": [
    "## Required libraries and configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed24cf4d-69ca-4459-bcd4-81f9086f17e2",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2abf80b1-6fbd-498c-bc70-2dfd12f18f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import List, Tuple\n",
    "\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from flwr.common import Metrics\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc69989-8a52-4a6d-a4be-a6fd0cad0f9c",
   "metadata": {},
   "source": [
    "Define some parameters for the simulation, such as the number of clients in the federated scenario, the number of federated rounds, the number of epochs of each client before communicating, and the batch size for training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ff34a93-03a1-44b4-b9b1-4d7b2ef2e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some parameters\n",
    "NUM_CLIENTS = 10 # Number of clients in the federated scenario\n",
    "NUM_ROUNDS = 10 # Number of learning rounds in the federated computation\n",
    "NUM_EPOCHS = 5 # Number of epochs that the local dataset is seen each round\n",
    "BATCH_SIZE = 20 # Batch size for training phase\n",
    "\n",
    "# Define the seed for random numbers\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128567f7-6bb0-491c-a601-033bdc7d8546",
   "metadata": {},
   "source": [
    "## Loading and preparing the input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ced738-266c-4bc6-beb0-c201789a6235",
   "metadata": {},
   "source": [
    "Load the MNIST dataset from torchvision. Later, split evenly and randomly the available training and testing data among the clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "120e68dc-a5a1-4472-8316-220389bcecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and transform MNIST (train and test)\n",
    "mnist_train = MNIST(\"./dataset\", train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = MNIST(\"./dataset\", train=False, download=True, transform=transforms.ToTensor())\n",
    "    \n",
    "# For simulation purposes, we select a subset (10%) of the original data\n",
    "# mnist_train = Subset(mnist_train, list(range(len(mnist_train)//10)))\n",
    "# mnist_test = Subset(mnist_test, list(range(len(mnist_test)//10)))\n",
    "\n",
    "# Split training and testing sets into NUM_CLIENTS partitions to simulate the individual datasets\n",
    "train_lengths = [len(mnist_train) // NUM_CLIENTS] * NUM_CLIENTS\n",
    "test_lengths = [len(mnist_test) // NUM_CLIENTS] * NUM_CLIENTS\n",
    "train_splits = random_split(mnist_train, train_lengths, torch.Generator().manual_seed(seed))\n",
    "test_splits = random_split(mnist_test, test_lengths, torch.Generator().manual_seed(seed))\n",
    "\n",
    "# Create DataLoaders for each client\n",
    "train_data = []\n",
    "test_data = []\n",
    "for i in range(NUM_CLIENTS):\n",
    "    train_data.append(DataLoader(train_splits[i], batch_size=BATCH_SIZE, shuffle=True))\n",
    "    test_data.append(DataLoader(test_splits[i], batch_size=BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4f1d6e-1ba7-4106-815e-27a73f8c85a0",
   "metadata": {},
   "source": [
    "## Create a Deep Learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217615a2-c3d1-48a8-8e93-722f6287b9ef",
   "metadata": {},
   "source": [
    "For a fair comparison with the rest of frameworks, here we propose two different network architectures: one with a CNN layer, which are widely used for image classification, and another one with only dense layers.\n",
    "\n",
    "Although these architectures are used here, note that any other network architecture supported by pytorch can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e3efb8-6d10-4690-8d9e-47502415a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network with a CNN\n",
    "class CNN_Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(CNN_Net, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(32 * 14 * 14, 10) \n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)        \n",
    "        return out\n",
    "\n",
    "# Define network with only dense/linear layers\n",
    "class Dense_Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Dense_Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        # The Relu and softmax layers may be used in forward method without defining in __init__\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f0658-5d27-4b3c-b8c0-aff191aab10e",
   "metadata": {},
   "source": [
    "Define the methods for training and evaluating the model in each local client. This methods receive the network to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7047559-0546-4977-ae78-429f45f1032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, epochs: int, verbose=True):\n",
    "    # Indicate the loss and optimizer to use\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    \n",
    "    # Train each epoch with local data\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "            \n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        \n",
    "    if verbose:\n",
    "        print(f\"Train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "def test(net, testloader):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c90245-0dbc-4ef3-9af0-33523fca66ef",
   "metadata": {},
   "source": [
    "## Training in the federated scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236e58ee-2075-44f6-a9ca-dfeb4ca88ba9",
   "metadata": {},
   "source": [
    "First, we create a FlowerClient class, that includes the information of each simulated client. The class has three methods:\n",
    " * `get_parameters`: Get the parameters of the model to send them to the server\n",
    " * `fit`: Reveives the model parameters from the server, trains it with local data, and return the updated model parameters to the server\n",
    " * `evaluate`: Receives the model from the server and evaluates it with local data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bce79cd7-3bc0-493a-aa88-739be7fa061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63e43d54-1d29-45a0-936f-aa3abd7d3ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, net, trainloader, testloader=None):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        if testloader is None:\n",
    "            print('Train data will be used as test data too.')\n",
    "            self.testloader = trainloader\n",
    "        else:\n",
    "            self.testloader = testloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=NUM_EPOCHS)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.testloader)\n",
    "        return float(loss), len(self.testloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56c4009-9db6-42f7-b757-d5c14eed50c0",
   "metadata": {},
   "source": [
    "To simulate the federated scenario in a single machine, the client_fn method allows to create FlowerClients on demand, given the client id.\n",
    "\n",
    "Note that each client is passed both training and testing local data, so the evaluation over test data is done during the simulation itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d612e9e-41e4-41ce-a48e-5cdd1e527e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    # Load model\n",
    "    net = CNN_Net().to(DEVICE)\n",
    "\n",
    "    # Note: each client gets a different train/test data\n",
    "    trainloader = train_data[int(cid)]\n",
    "    testloader = test_data[int(cid)]\n",
    "\n",
    "    # Create a  single Flower client representing a single organization\n",
    "    return FlowerClient(net, trainloader, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b5a78-6cf5-4a25-9f3b-4421c92906e3",
   "metadata": {},
   "source": [
    "In order to show averaged evaluations metrics beyond loss, we should define a method to do that; in this case, the accuracy is weighted averaged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e3cc4d6-c4b6-434d-955e-cf522b4a17c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab836a-980f-439e-935f-d94480736153",
   "metadata": {},
   "source": [
    "Train with weighted FedAvg algorithm.\n",
    "\n",
    "Then, start the simulation indicating the method to create clients, the number of clients in the simulation, the number of rounds, and the strategy (i.e., the FedAvg strategy to combine local updates). The simulation covers both the federated model training as well as evaluating the model with each local test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "217405e7-5db6-466a-95cf-d7d8fdae1eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-02-16 19:36:27,046 | app.py:142 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
      "2023-02-16 19:36:29,070\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "INFO flwr 2023-02-16 19:36:30,257 | app.py:176 | Flower VCE: Ray initialized with resources: {'object_store_memory': 3795530956.0, 'memory': 7591061915.0, 'node:192.168.1.131': 1.0, 'CPU': 12.0}\n",
      "INFO flwr 2023-02-16 19:36:30,259 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2023-02-16 19:36:30,260 | server.py:270 | Requesting initial parameters from one random client\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/jose/flower/venv_flower/lib/python3.10/site-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   aiogrpc.init_grpc_aio()\n",
      "INFO flwr 2023-02-16 19:36:31,227 | server.py:274 | Received initial parameters from one random client\n",
      "INFO flwr 2023-02-16 19:36:31,228 | server.py:88 | Evaluating initial parameters\n",
      "INFO flwr 2023-02-16 19:36:31,228 | server.py:101 | FL starting\n",
      "DEBUG flwr 2023-02-16 19:36:31,229 | server.py:215 | fit_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546280)\u001b[0m Train loss 0.0030265888199210167, accuracy 0.9835\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546282)\u001b[0m Train loss 0.002852827776223421, accuracy 0.9846666666666667\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546287)\u001b[0m Train loss 0.002905048429965973, accuracy 0.984\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546286)\u001b[0m Train loss 0.0027102187741547823, accuracy 0.985\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546285)\u001b[0m Train loss 0.0028616958297789097, accuracy 0.9863333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546288)\u001b[0m Train loss 0.002865815768018365, accuracy 0.9863333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546281)\u001b[0m Train loss 0.0032659205608069897, accuracy 0.982\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546289)\u001b[0m Train loss 0.0029636197723448277, accuracy 0.9831666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546283)\u001b[0m Train loss 0.002695698058232665, accuracy 0.9851666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:37:57,391 | server.py:229 | fit_round 1 received 10 results and 0 failures\n",
      "WARNING flwr 2023-02-16 19:37:57,401 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2023-02-16 19:37:57,401 | server.py:165 | evaluate_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546284)\u001b[0m Train loss 0.0024995296262204647, accuracy 0.9871666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:37:59,170 | server.py:179 | evaluate_round 1 received 10 results and 0 failures\n",
      "DEBUG flwr 2023-02-16 19:37:59,171 | server.py:215 | fit_round 2: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546280)\u001b[0m Train loss 0.0010164737468585372, accuracy 0.9958333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546288)\u001b[0m Train loss 0.000936980708502233, accuracy 0.9946666666666667\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546283)\u001b[0m Train loss 0.0009536045254208148, accuracy 0.9961666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546286)\u001b[0m Train loss 0.0009991395054385066, accuracy 0.9965\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546282)\u001b[0m Train loss 0.0009256433695554733, accuracy 0.9953333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546287)\u001b[0m Train loss 0.0007064730161800981, accuracy 0.9973333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:39:23,058 | server.py:229 | fit_round 2 received 10 results and 0 failures\n",
      "DEBUG flwr 2023-02-16 19:39:23,066 | server.py:165 | evaluate_round 2: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546281)\u001b[0m Train loss 0.0009876148542389274, accuracy 0.9953333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546285)\u001b[0m Train loss 0.0009151339763775468, accuracy 0.9953333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546289)\u001b[0m Train loss 0.0008823777898214757, accuracy 0.9963333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546284)\u001b[0m Train loss 0.0008183348109014332, accuracy 0.9966666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:39:24,838 | server.py:179 | evaluate_round 2 received 10 results and 0 failures\n",
      "DEBUG flwr 2023-02-16 19:39:24,839 | server.py:215 | fit_round 3: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546285)\u001b[0m Train loss 0.00029151630587875843, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546286)\u001b[0m Train loss 0.0005136273102834821, accuracy 0.9983333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546289)\u001b[0m Train loss 0.00048484178842045367, accuracy 0.9985\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546287)\u001b[0m Train loss 0.0005915068904869258, accuracy 0.9978333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546282)\u001b[0m Train loss 0.00047524337423965335, accuracy 0.9988333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546284)\u001b[0m Train loss 0.00045469237375073135, accuracy 0.9981666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546280)\u001b[0m Train loss 0.00027323950780555606, accuracy 0.9996666666666667\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546283)\u001b[0m Train loss 0.00048728002002462745, accuracy 0.9986666666666667\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546288)\u001b[0m Train loss 0.0003682674141600728, accuracy 0.9993333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:40:48,727 | server.py:229 | fit_round 3 received 10 results and 0 failures\n",
      "DEBUG flwr 2023-02-16 19:40:48,744 | server.py:165 | evaluate_round 3: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546281)\u001b[0m Train loss 0.0004914847668260336, accuracy 0.9983333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:40:50,474 | server.py:179 | evaluate_round 3 received 10 results and 0 failures\n",
      "DEBUG flwr 2023-02-16 19:40:50,475 | server.py:215 | fit_round 4: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546286)\u001b[0m Train loss 0.0004113468748982996, accuracy 0.9981666666666666\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546280)\u001b[0m Train loss 0.0002632953692227602, accuracy 0.9995\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546284)\u001b[0m Train loss 0.0002624709450174123, accuracy 0.9995\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546282)\u001b[0m Train loss 0.0002887472801376134, accuracy 0.999\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546289)\u001b[0m Train loss 0.00031553886947222054, accuracy 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:42:16,126 | server.py:229 | fit_round 4 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546287)\u001b[0m Train loss 0.00027761192177422345, accuracy 0.999\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546281)\u001b[0m Train loss 0.00027054475503973663, accuracy 0.9996666666666667\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546288)\u001b[0m Train loss 0.0001896005414891988, accuracy 0.9998333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:42:16,138 | server.py:165 | evaluate_round 4: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546283)\u001b[0m Train loss 0.000268075818894431, accuracy 0.9996666666666667\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546285)\u001b[0m Train loss 0.0002216798602603376, accuracy 0.9996666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:42:18,928 | server.py:179 | evaluate_round 4 received 10 results and 0 failures\n",
      "DEBUG flwr 2023-02-16 19:42:18,931 | server.py:215 | fit_round 5: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546280)\u001b[0m Train loss 0.00018391611229162663, accuracy 0.9996666666666667\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546282)\u001b[0m Train loss 0.0002668464439921081, accuracy 0.999\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546288)\u001b[0m Train loss 0.000249528675340116, accuracy 0.9993333333333333\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546285)\u001b[0m Train loss 0.00019963747763540596, accuracy 0.9996666666666667\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546287)\u001b[0m Train loss 0.00021169106184970587, accuracy 0.9995\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546289)\u001b[0m Train loss 0.00016772562230471522, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546284)\u001b[0m Train loss 0.00011549867485882714, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546283)\u001b[0m Train loss 0.00016075668099801987, accuracy 0.9998333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546286)\u001b[0m Train loss 0.00010481283970875666, accuracy 0.9998333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:44:11,520 | server.py:229 | fit_round 5 received 10 results and 0 failures\n",
      "DEBUG flwr 2023-02-16 19:44:11,532 | server.py:165 | evaluate_round 5: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546281)\u001b[0m Train loss 0.00017553775978740305, accuracy 0.9996666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:44:14,791 | server.py:179 | evaluate_round 5 received 10 results and 0 failures\n",
      "DEBUG flwr 2023-02-16 19:44:14,791 | server.py:215 | fit_round 6: strategy sampled 10 clients (out of 10)\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 3463 MiB, 117 objects, write throughput 258 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546284)\u001b[0m Train loss 0.00013564729306381196, accuracy 0.9996666666666667\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546287)\u001b[0m Train loss 0.00015160466136876494, accuracy 0.9995\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546289)\u001b[0m Train loss 0.00019675302610266954, accuracy 0.9998333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546282)\u001b[0m Train loss 0.0001459810882806778, accuracy 0.9996666666666667\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546281)\u001b[0m Train loss 8.056170918280259e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546285)\u001b[0m Train loss 6.823216244811192e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546286)\u001b[0m Train loss 0.00014715157158207148, accuracy 0.9998333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546280)\u001b[0m Train loss 0.00014233063848223537, accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:46:15,459 | server.py:229 | fit_round 6 received 10 results and 0 failures\n",
      "DEBUG flwr 2023-02-16 19:46:15,473 | server.py:165 | evaluate_round 6: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546283)\u001b[0m Train loss 0.00012830054038204253, accuracy 0.9998333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546288)\u001b[0m Train loss 0.0001239950506715104, accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:46:18,639 | server.py:179 | evaluate_round 6 received 10 results and 0 failures\n",
      "DEBUG flwr 2023-02-16 19:46:18,640 | server.py:215 | fit_round 7: strategy sampled 10 clients (out of 10)\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 4367 MiB, 144 objects, write throughput 268 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546288)\u001b[0m Train loss 6.159431359265e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546285)\u001b[0m Train loss 0.00011292295675957575, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546282)\u001b[0m Train loss 0.00019497446191962808, accuracy 0.9995\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546286)\u001b[0m Train loss 8.827290002955124e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546281)\u001b[0m Train loss 7.418965105898678e-05, accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:48:18,671 | server.py:229 | fit_round 7 received 10 results and 0 failures\n",
      "DEBUG flwr 2023-02-16 19:48:18,688 | server.py:165 | evaluate_round 7: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546284)\u001b[0m Train loss 8.346053800778463e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546280)\u001b[0m Train loss 0.00010906363604590297, accuracy 0.9998333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546283)\u001b[0m Train loss 0.00021163022029213607, accuracy 0.999\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546289)\u001b[0m Train loss 8.528500620741397e-05, accuracy 0.9998333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546287)\u001b[0m Train loss 0.00013074188609607518, accuracy 0.9998333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:48:21,355 | server.py:179 | evaluate_round 7 received 10 results and 0 failures\n",
      "DEBUG flwr 2023-02-16 19:48:21,356 | server.py:215 | fit_round 8: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546282)\u001b[0m Train loss 7.967185229063034e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546286)\u001b[0m Train loss 9.805135778151453e-05, accuracy 0.9998333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546285)\u001b[0m Train loss 6.577933527296409e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546284)\u001b[0m Train loss 0.00013160523667465895, accuracy 0.9995\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546283)\u001b[0m Train loss 8.076574158621952e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546288)\u001b[0m Train loss 8.691713446751237e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546281)\u001b[0m Train loss 5.135074752615765e-05, accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:50:20,813 | server.py:229 | fit_round 8 received 10 results and 0 failures\n",
      "DEBUG flwr 2023-02-16 19:50:20,822 | server.py:165 | evaluate_round 8: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546287)\u001b[0m Train loss 0.00012510221858974546, accuracy 0.9995\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546289)\u001b[0m Train loss 0.00012711483577731997, accuracy 0.9998333333333334\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546280)\u001b[0m Train loss 4.661503044189885e-05, accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:50:23,808 | server.py:179 | evaluate_round 8 received 10 results and 0 failures\n",
      "DEBUG flwr 2023-02-16 19:50:23,808 | server.py:215 | fit_round 9: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546280)\u001b[0m Train loss 8.119054837152362e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546283)\u001b[0m Train loss 4.260951391188428e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546282)\u001b[0m Train loss 3.380142879905179e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546281)\u001b[0m Train loss 5.476405203808099e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546288)\u001b[0m Train loss 6.277037755353376e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546285)\u001b[0m Train loss 5.6029683037195355e-05, accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:52:23,876 | server.py:229 | fit_round 9 received 10 results and 0 failures\n",
      "DEBUG flwr 2023-02-16 19:52:23,886 | server.py:165 | evaluate_round 9: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546284)\u001b[0m Train loss 9.257064084522426e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546289)\u001b[0m Train loss 7.376000576186925e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546286)\u001b[0m Train loss 8.607583004049957e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546287)\u001b[0m Train loss 5.473859710036777e-05, accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:52:26,395 | server.py:179 | evaluate_round 9 received 10 results and 0 failures\n",
      "DEBUG flwr 2023-02-16 19:52:26,397 | server.py:215 | fit_round 10: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546283)\u001b[0m Train loss 5.3836767619941384e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546282)\u001b[0m Train loss 6.57454802421853e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546280)\u001b[0m Train loss 4.4675969547824934e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546285)\u001b[0m Train loss 4.5096483518136665e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546287)\u001b[0m Train loss 3.079467933275737e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546289)\u001b[0m Train loss 8.671320392750204e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546286)\u001b[0m Train loss 4.0988037653733045e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546281)\u001b[0m Train loss 5.4243697377387434e-05, accuracy 1.0\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=546288)\u001b[0m Train loss 7.267542969202623e-05, accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:54:22,506 | server.py:229 | fit_round 10 received 10 results and 0 failures\n",
      "DEBUG flwr 2023-02-16 19:54:22,517 | server.py:165 | evaluate_round 10: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=546284)\u001b[0m Train loss 0.00029514438938349485, accuracy 0.9983333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-02-16 19:54:24,533 | server.py:179 | evaluate_round 10 received 10 results and 0 failures\n",
      "INFO flwr 2023-02-16 19:54:24,534 | server.py:144 | FL finished in 1073.3046612579992\n",
      "INFO flwr 2023-02-16 19:54:24,535 | app.py:198 | app_fit: losses_distributed [(1, 0.003725907833909151), (2, 0.0026956475416038297), (3, 0.002458076979863108), (4, 0.002361149704503805), (5, 0.0023937608808074396), (6, 0.002385528113156715), (7, 0.0023698440767813737), (8, 0.0024062374137010126), (9, 0.0024627016643065875), (10, 0.0024916819895731235)]\n",
      "INFO flwr 2023-02-16 19:54:24,535 | app.py:199 | app_fit: metrics_distributed {'accuracy': [(1, 0.977), (2, 0.9833000000000002), (3, 0.9840999999999999), (4, 0.9842000000000001), (5, 0.9856), (6, 0.9862), (7, 0.9867999999999999), (8, 0.9865000000000002), (9, 0.9867999999999999), (10, 0.9872)]}\n",
      "INFO flwr 2023-02-16 19:54:24,536 | app.py:200 | app_fit: losses_centralized []\n",
      "INFO flwr 2023-02-16 19:54:24,536 | app.py:201 | app_fit: metrics_centralized {}\n"
     ]
    }
   ],
   "source": [
    "# Create FedAvg strategy, indicating the metric aggregation function\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    evaluate_metrics_aggregation_fn=weighted_average\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "fl_sim = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d71eda6-e109-4610-a686-031eca5c7404",
   "metadata": {},
   "source": [
    "## Evaluation with test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f880ae9-dd18-4da9-adb9-8fb88bcb64f8",
   "metadata": {},
   "source": [
    "The evaluation has been done during the simulation. Following, we show the averaged results over test data.\n",
    "The result of the simulation includes the results on all rounds, so we retrieve those of the last round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e24f3677-2792-41fe-9c8f-b14d7d82a6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data, \t Loss=0.0025, \t Accuracy=0.9872\n"
     ]
    }
   ],
   "source": [
    "print('Test data, \\t Loss={:.4f}, \\t Accuracy={:.4f}'.format(fl_sim.losses_distributed[-1][1], fl_sim.metrics_distributed['accuracy'][-1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6c49527-6bcb-4ed3-91f8-567edab15c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 0.003725907833909151\n",
       "\tround 2: 0.0026956475416038297\n",
       "\tround 3: 0.002458076979863108\n",
       "\tround 4: 0.002361149704503805\n",
       "\tround 5: 0.0023937608808074396\n",
       "\tround 6: 0.002385528113156715\n",
       "\tround 7: 0.0023698440767813737\n",
       "\tround 8: 0.0024062374137010126\n",
       "\tround 9: 0.0024627016643065875\n",
       "\tround 10: 0.0024916819895731235\n",
       "History (metrics, distributed):\n",
       "{'accuracy': [(1, 0.977), (2, 0.9833000000000002), (3, 0.9840999999999999), (4, 0.9842000000000001), (5, 0.9856), (6, 0.9862), (7, 0.9867999999999999), (8, 0.9865000000000002), (9, 0.9867999999999999), (10, 0.9872)]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl_sim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
