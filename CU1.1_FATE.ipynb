{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38f8aa51",
   "metadata": {},
   "source": [
    "# **USE CASE 1.1.** Image classification in FATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff6ab1b",
   "metadata": {},
   "source": [
    "## Initialize FATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d21bbe",
   "metadata": {},
   "source": [
    "Prior to the execution of the FATE code, the user may initialize FATE as seen in their [webpage](https://fate.readthedocs.io/en/latest/deploy/standalone-deploy/#3-install-fate-in-the-host-using-the-compiled-installer). The following commands are commented, so the user may uncomment them if needed; i.e., if FATE has not been initialized so far in this session. We assume that FATE has been already installed as indicated in their [webpage](https://fate.readthedocs.io/en/latest/deploy/standalone-deploy/#3-install-fate-in-the-host-using-the-compiled-installer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f07b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to the folder where FATE standalone has been downloaded. Modify the path as required.\n",
    "#!cd /path/to/standalone_fate_install_1.10.0_release\n",
    "\n",
    "# Start FATE service\n",
    "#!bash bin/init.sh start\n",
    "\n",
    "# Load environment variables\n",
    "#!source bin/init_env.sh\n",
    "\n",
    "# Initialize FATE's pipeline\n",
    "!pipeline init --ip 127.0.0.1 --port 9380"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a54d186",
   "metadata": {},
   "source": [
    "## Required libraries and configuration\n",
    "\n",
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca040740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch as t\n",
    "from torch import nn\n",
    "from pipeline import fate_torch_hook\n",
    "from pipeline.component import HomoNN\n",
    "from pipeline.backend.pipeline import PipeLine\n",
    "from pipeline.component import Reader, Evaluation, DataTransform\n",
    "from pipeline.interface import Data, Model\n",
    "\n",
    "from pipeline.component.nn import DatasetParam\n",
    "from pipeline.component.homo_nn import TrainerParam\n",
    "\n",
    "t = fate_torch_hook(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856e7b9c",
   "metadata": {},
   "source": [
    "Define some parameters for the simulation, such as the guest and hosts ids, the number of clients in the federated scenario, the number of federated rounds, the number of epochs of each client before communicating, the batch size for training phase, and the seed for random numbers.\n",
    "\n",
    "FATE's clients must be assigned to guest and host roles. The guest will be by default the one that initiates the learning, so in this case, one guest and four hosts are defined. Note that, when including more than four hosts, FATE was not able to execute the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb7a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind data path to name & namespace\n",
    "fate_project_path = os.path.abspath('/workspace/FATE/')\n",
    "\n",
    "# Roles\n",
    "guest = 10000\n",
    "hosts = [10001, 10002, 10003, 10004]\n",
    "arbiter = 9999\n",
    "\n",
    "# Some parameters\n",
    "NUM_CLIENTS = len(hosts) + 1 # The number of clients is given by the number of hosts + the guest\n",
    "NUM_ROUNDS = 10 # Number of learning rounds in the federated computation\n",
    "NUM_EPOCHS = 5 # Number of epochs FATE uses a pipeline with components that are connected between them once added.\n",
    "BATCH_SIZE = 20 # Batch size for training phase\n",
    "\n",
    "# Seed for random numbers\n",
    "seed = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a72cb81",
   "metadata": {},
   "source": [
    "FATE uses a pipeline with components that are connected between them once added.\n",
    "First of all, we initialize the pipeline and set the roles of each client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e54c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pipeline\n",
    "pipeline = PipeLine()\n",
    "\n",
    "# Set job initiator; the guest initiates the process\n",
    "pipeline.set_initiator(role='guest', party_id=guest)\n",
    "\n",
    "# Set participants information\n",
    "pipeline.set_roles(guest=guest, host=hosts, arbiter=arbiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7825810",
   "metadata": {},
   "source": [
    "## Loading and preparing the input data\n",
    "\n",
    "The data to be used has been downloaded from [this GitHub repository](https://github.com/teavanist/MNIST-JPG), and later organized in folders: each client has two folders: training and testing data; these folders are later divided by digits. Note that FATE also provides a smaller subset of MNIST that can be downloadad in [this link](https://webank-ai-1251170195.cos.ap-guangzhou.myqcloud.com/fate/examples/data/mnist.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c80af4e",
   "metadata": {},
   "source": [
    "Define the data tables, which will be used later in the FATE job configuration. We use several partitions of the MNIST dataset, one for each of the clients, with different images. We define different tables for training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa1f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables for each client's training data\n",
    "train_datas = [None]*NUM_CLIENTS\n",
    "for i in range(NUM_CLIENTS):\n",
    "    train_datas[i] = {\"name\": \"mnist_train\" + str(i), \"namespace\": \"experiment\"}\n",
    "\n",
    "# Different data paths for each client\n",
    "# The path may differ depending where the user has download the mnist images\n",
    "train_data_paths = [None]*NUM_CLIENTS\n",
    "for i in range(NUM_CLIENTS): \n",
    "    train_data_paths[i] = fate_project_path + '/c' + str(i) + '_train'\n",
    "\n",
    "for i in range(NUM_CLIENTS): \n",
    "    pipeline.bind_table(name=train_datas[i]['name'], \n",
    "                        namespace=train_datas[i]['namespace'], \n",
    "                        path=train_data_paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a1806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables for each client's testing data\n",
    "test_datas = [None]*NUM_CLIENTS\n",
    "for i in range(NUM_CLIENTS):\n",
    "    test_datas[i] = {\"name\": \"mnist_test\" + str(i), \"namespace\": \"experiment\"}\n",
    "\n",
    "test_data_paths = [None]*NUM_CLIENTS\n",
    "for i in range(NUM_CLIENTS): \n",
    "    test_data_paths[i] = fate_project_path + '/c' + str(i) + '_test'\n",
    "\n",
    "for i in range(NUM_CLIENTS): \n",
    "    pipeline.bind_table(name=test_datas[i]['name'], \n",
    "                        namespace=test_datas[i]['namespace'], \n",
    "                        path=test_data_paths[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b56e1f",
   "metadata": {},
   "source": [
    "The ``Reader`` component, that will later be included to in the pipeline, is in charge of reading the data. We define different readers for either training or testing datasets, since they will be used at different stages of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ef981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Reader for training data\n",
    "reader_train = Reader(name=\"reader_train\")\n",
    "\n",
    "# Set the data of each client. The guest will be defined as the client 0, and the rest will be the hosts.\n",
    "reader_train.get_party_instance(role='guest', party_id=guest).component_param(table=train_datas[0])\n",
    "for i in range(1, NUM_CLIENTS):\n",
    "    reader_train.get_party_instance(role='host', party_id=hosts[i-1]).component_param(table=train_datas[i])\n",
    "\n",
    "# Configure Reader for testing data\n",
    "reader_test = Reader(name=\"reader_test\")\n",
    "\n",
    "reader_test.get_party_instance(role='guest', party_id=guest).component_param(table=test_datas[0])\n",
    "for i in range(1,NUM_CLIENTS):\n",
    "    reader_test.get_party_instance(role='host', party_id=hosts[i-1]).component_param(table=test_datas[i])\n",
    "\n",
    "\n",
    "dataset_param = DatasetParam(dataset_name='mnist_dataset', flatten_feature=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c81aae",
   "metadata": {},
   "source": [
    "## Create a Deep Learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fbe2fe",
   "metadata": {},
   "source": [
    "It should be highlighted that,  at the time of developing this work, FATE only support Dense/Linear layers when developing a Neural Network (NN) for Horizontal/Vertical Federated Learning. To check the supported layers, check this [link](https://fate.readthedocs.io/en/latest/federatedml_component/homo_nn/#supported-layers_1). Besides, it only supports PyTorch as the framework for developing NN for HFL.\n",
    "\n",
    "Therefore, in next cell we define a model based on PyTorch with only linear layers. Later, the HomoNN class facilitates the integration of such deep learning model into the FATE environment. The HomoNN class receives some parameters such as the loss, optimizer, or federated training process to be follwed. Specifically, the trainer process uses the federated average aggregator, and note that the ``epochs`` parameter stands for the total number of epochs (including those of only local training), but the results are aggregated each ``aggregate_every_n_epoch`` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beb2633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model with linear layers\n",
    "model = t.nn.Sequential(\n",
    "    t.nn.Linear(784, 32),\n",
    "    t.nn.ReLU(),\n",
    "    t.nn.Linear(32, 10),\n",
    "    t.nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "nn_0 = HomoNN(name='nn_0',\n",
    "              model=model,\n",
    "              loss=t.nn.CrossEntropyLoss(),\n",
    "              optimizer=t.optim.Adam(\n",
    "                  model.parameters(), \n",
    "                  lr=0.001\n",
    "              ),\n",
    "              dataset=dataset_param, \n",
    "              trainer=TrainerParam(\n",
    "                  trainer_name='fedavg_trainer', \n",
    "                  epochs=NUM_EPOCHS * NUM_ROUNDS,\n",
    "                  aggregate_every_n_epoch=NUM_EPOCHS,\n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  validation_freqs=NUM_EPOCHS\n",
    "              ),\n",
    "              torch_seed=seed # random seed\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efa1129",
   "metadata": {},
   "source": [
    "In addition to the previous model, we define another one which will later be a copy of the previous. That is needed in order to feed each of them with either training or testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53a7aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_1 = HomoNN(name=\"nn_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4976a200",
   "metadata": {},
   "source": [
    "## Configure the Pipeline and its components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93146744",
   "metadata": {},
   "source": [
    "FATE creates a Pipeline and then add the components that we want to use to train/predict in the federated scenario. They are added in the given order of task execution.\n",
    "\n",
    "We add the ``Reader`` and ``HomoNN`` components to the pipeline. Besides, we define a new component to perform the evaluation, and add it to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbfd0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data readers\n",
    "pipeline.add_component(reader_train)\n",
    "pipeline.add_component(reader_test)\n",
    "\n",
    "# Add nn_0; its input is the training data\n",
    "pipeline.add_component(nn_0, data=Data(train_data=reader_train.output.data))\n",
    "\n",
    "# Add nn_1; its input is the testing data, and the model is the nn_0 previously trained\n",
    "pipeline.add_component(nn_1, data=Data(test_data=reader_test.output.data),\n",
    "                       model=Model(model=nn_0.output.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e8861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the evaluation strategy\n",
    "evaluation_0 = Evaluation(name='eval_0', eval_type='multi')\n",
    "\n",
    "# Add to the pipeline\n",
    "pipeline.add_component(evaluation_0, data=Data(data=[nn_0.output.data, nn_1.output.data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ca10ec",
   "metadata": {},
   "source": [
    "## Training and testing in the federated scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1085379",
   "metadata": {},
   "source": [
    "Once we have the pipeline with all the components ready, we just compile the pipeline and use the fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313cf1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile pipeline once finished adding modules, this step will form conf and dsl files for running job\n",
    "pipeline.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb1bd81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "pipeline.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea5934c",
   "metadata": {},
   "source": [
    "We can check the results of the model in different ways. The first one is using the components with the evaluation strategy defined in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5ca04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# query component summary\n",
    "pipeline.get_component('nn_0').get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf717599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline.get_component('nn_0').get_output_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c53fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.get_component('nn_1').get_output_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0834db",
   "metadata": {},
   "source": [
    "FATE does not provide the loss or accuracy metrics in testing, but we may calculate the accuracy given the prediction information of previous table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42082a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(pipeline.get_component('nn_1').get_output_data()['label'])\n",
    "predicted = list(pipeline.get_component('nn_1').get_output_data()['predict_result'])\n",
    "accuracy = sum(1 for x,y in zip(labels,predicted) if x == y) / float(len(labels))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c656db2",
   "metadata": {},
   "source": [
    "## FATE board"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb35fac2",
   "metadata": {},
   "source": [
    "Using the board provided by the FATE framework (By default, available at: [127.0.0.1:8080](http://127.0.0.1:8080)), we can see the results in graphics, instead of using only the output of the summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c512aae",
   "metadata": {},
   "source": [
    "![nn_0](nn_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6907fa",
   "metadata": {},
   "source": [
    "![evaluation_0](evaluation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ddc30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
